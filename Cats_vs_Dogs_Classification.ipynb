{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61f865c-9763-44fe-b8f2-f626006a9c58",
   "metadata": {},
   "source": [
    "**Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8902013-e7a8-4b03-ba4a-f22805d5a798",
   "metadata": {},
   "source": [
    "I used a VGG16 and then added new layers to better learn patterns of cats and dogs. Originally, I tried a CNN and that yielded an accuracy of about 85%. Then I tried VGG16 and got around 90%. Other models I tried were ResNet50 and EfficientNetB0 but they outputted very low accuraccy scores. So I decided to use VGG16 as my base. I then used bianary cross-entropy as my loss function and Adam as my optimizer. This helped with efficient learning. I only did 20 epochs with halting procautions. In hindsight I could have added more. Finally, I evaluated the model on Accuracy and log loss and then outputted my findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f3525-165b-45a8-a001-595374f6557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Dense, Activation,\n",
    "    Dropout, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator, load_img, img_to_array\n",
    ")\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "train_path = \"/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\"\n",
    "test_path = \"/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\"\n",
    "\n",
    "files = \"/kaggle/working/HW4_2\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(train_path, 'r') as zipp:\n",
    "    zipp.extractall(files)\n",
    "    \n",
    "with zipfile.ZipFile(test_path, 'r') as zipp:\n",
    "    zipp.extractall(files)\n",
    "\n",
    "base_dir = \"/kaggle/working/HW4_2/train\"\n",
    "cat_dir = os.path.join(base_dir, \"cat\")\n",
    "dog_dir = os.path.join(base_dir, \"dog\")\n",
    "\n",
    "# Create folders\n",
    "os.makedirs(cat_dir, exist_ok=True)\n",
    "os.makedirs(dog_dir, exist_ok=True)\n",
    "\n",
    "# Move only .jpg files that start with \"cat\" or \"dog\"\n",
    "for filename in os.listdir(base_dir):\n",
    "    src_path = os.path.join(base_dir, filename)\n",
    "    \n",
    "    if os.path.isfile(src_path):  # ✅ Only move actual files\n",
    "        if filename.startswith(\"cat\"):\n",
    "            shutil.move(src_path, os.path.join(cat_dir, filename))\n",
    "        elif filename.startswith(\"dog\"):\n",
    "            shutil.move(src_path, os.path.join(dog_dir, filename))\n",
    "\n",
    "# === CONFIG ===\n",
    "img_rows, img_cols = 150, 150\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "train_dir = '/kaggle/working/HW4_2/train'\n",
    "test_dir = '/kaggle/working/HW4_2/test'\n",
    "\n",
    "# === ADVANCED DATA AUGMENTATION ===\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# === LOAD VGG16 AND UNFREEZE LAST 4 LAYERS ===\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# === TUNED CLASSIFIER HEAD ===\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# === COMPILE ===\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === CALLBACKS ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n",
    "]\n",
    "\n",
    "# === TRAIN ===\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === EVALUATE ===\n",
    "val_preds = model.predict(val_generator, verbose=0)\n",
    "y_true = val_generator.classes\n",
    "val_acc = accuracy_score(y_true, (val_preds > 0.5).astype(int))\n",
    "val_logloss = log_loss(y_true, val_preds[:len(y_true)])\n",
    "\n",
    "print(f\"\\n✅ Tuned VGG16 Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"✅ Tuned VGG16 Validation Log Loss: {val_logloss:.4f}\")\n",
    "\n",
    "\n",
    "# === LOAD TEST IMAGES ===\n",
    "test_images = sorted([f for f in os.listdir(test_dir) if f.endswith(\".jpg\")])\n",
    "X_test, ids = [], []\n",
    "\n",
    "for fname in test_images:\n",
    "    img_path = os.path.join(test_dir, fname)\n",
    "    img = load_img(img_path, target_size=(img_rows, img_cols))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    X_test.append(img_array)\n",
    "    ids.append(int(fname.split('.')[0]))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# === PREDICT ===\n",
    "preds = model.predict(X_test, verbose=1)\n",
    "\n",
    "# === CREATE SUBMISSION CSV ===\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": ids,\n",
    "    \"label\": preds.flatten()\n",
    "})\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission.csv created and ready to upload to Kaggle.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
